{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "path_dir = './Final_data/one_week/'\n",
    "file_list = os.listdir(path_dir) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del file_list[26] \n",
    "len(file_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "cust_ip_list = [] \n",
    "\n",
    "for i in file_list:\n",
    "    tmp_df = pd.read_parquet(path_dir+i, engine='pyarrow')\n",
    "    tmp_df['stamp_inserted'] = pd.to_datetime(tmp_df['stamp_inserted'], format='%Y%m%d%H%M%S')\n",
    "    tmp_df.event.fillna(0, inplace=True)\n",
    "    df_list.append(tmp_df)\n",
    "    c_ip = tmp_df.iloc[0].cust_ip_no \n",
    "    cust_ip_list.append(c_ip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디도스 + 전체 시간이 있는 데이터 \n",
    "e_data = []\n",
    "\n",
    "for n, df in enumerate(df_list):\n",
    "    if len(df) >= 10080 and 1 in df.event.values :\n",
    "        if 1 in df.event.values:\n",
    "            df = df.drop_duplicates(['stamp_inserted'], keep='first')\n",
    "            if len(df) >= 10080:\n",
    "                df.reset_index(drop=True, inplace=True) \n",
    "                e_data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv = ['bytes', 'pkts',\n",
    "       'sip_entropy', 'dip_entropy', 'spt_entropy', 'dpt_entropy',\n",
    "       'proto_entropy', 'tcp_flags_entropy', 'icmp_ratio', 'tcp_ratio',\n",
    "       'udp_ratio', 'domestic_ratio', 'in_ratio', 'inner_ratio']\n",
    "iv1 = ['bytes', 'pkts',\n",
    "       'sip_entropy', 'dip_entropy', 'spt_entropy', 'dpt_entropy',\n",
    "       'proto_entropy', 'tcp_flags_entropy', 'icmp_ratio', 'tcp_ratio',\n",
    "       'udp_ratio', 'domestic_ratio', 'in_ratio', 'inner_ratio', 'cust_ip_no', 'event']\n",
    "features = len(iv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(e_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IP별 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "X_data = []\n",
    "y_data = [] \n",
    "for i in e_data:\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    y_data.append(i[['cust_ip_no', 'event']].values)\n",
    "    file_name = 'scaler_ip_{}.pkl'.format(i['cust_ip_no'].values[0]) \n",
    "    \n",
    "    i = scaler.fit_transform(i[iv].values) \n",
    "    X_data.append(i)\n",
    "    \n",
    "    joblib.dump(scaler, file_name) \n",
    "    \n",
    "# unseen data의 경우 scaler.partail_fit(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = joblib.load('scaler_ip_8879.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = []\n",
    "for x, y in zip(X_data, y_data):\n",
    "    data_ = np.concatenate((x, y), axis=1) \n",
    "    data_ = pd.DataFrame(data_, columns=iv1) \n",
    "    print(data_.iloc[0,-2])\n",
    "    new_data.append(data_)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "----몇 개씩 묶어서 해볼 때----\n",
    "# train_X_ae = np.concatenate((train_X_ae1, train_X_ae5, train_X_ae6), axis=0)\n",
    "# train_y_ae = np.concatenate((train_y_ae1, train_y_ae5, train_y_ae6), axis=0)\n",
    "# test_X_ae = np.concatenate((test_X_ae1, test_X_ae5, test_X_ae6), axis=0)\n",
    "# test_y_ae = np.concatenate((test_y_ae1, test_y_ae5, test_y_ae6), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "seq_time = 5\n",
    "\n",
    "normal_X = [] \n",
    "normal_y = []\n",
    "abnormal_X = [] \n",
    "abnormal_y = []\n",
    "\n",
    "\n",
    "for j in tqdm(range(len(new_data))):\n",
    "    normal_data = pd.DataFrame(columns=iv)\n",
    "    normal_label = []\n",
    "    abnormal_data = pd.DataFrame(columns=iv)\n",
    "    abnormal_label = []\n",
    "    for i in range(len(new_data[j]) - seq_time):        \n",
    "        input_x = new_data[j].iloc[i:i+seq_time, :-2]\n",
    "        label = new_data[j].iloc[i+seq_time-1, -1]\n",
    "        ip_NO = new_data[j].iloc[i+seq_time-1, -2]  \n",
    "        \n",
    "        if label == 0:\n",
    "            normal_data = pd.concat([normal_data, input_x], axis=0)\n",
    "            ip_label_set = (ip_NO, label)            \n",
    "            normal_label.append(ip_label_set)\n",
    "            \n",
    "        else :\n",
    "            abnormal_data = pd.concat([abnormal_data, input_x], axis=0)\n",
    "            ip_label_set = (ip_NO, label) \n",
    "            abnormal_label.append(ip_label_set)\n",
    "            \n",
    "    normal_X.append(normal_data)  #IP별 9개의 정상 데이터\n",
    "    normal_y.append(normal_label) \n",
    "    if len(abnormal_data) != 0:\n",
    "        abnormal_X.append(abnormal_data)\n",
    "        abnormal_y.append(abnormal_label)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip_idx = 0\n",
    "X_normal = normal_X[ip_idx].values.reshape(-1, 5, 14) \n",
    "X_abnormal = abnormal_X[ip_idx].values.reshape(-1, 5, 14) \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_X_ae, test_X_ae, train_y_ae, test_y_ae = train_test_split(X_normal, normal_y[ip_idx], test_size=0.1, shuffle=True)\n",
    "\n",
    "print(train_X_ae.shape) \n",
    "print(test_X_ae.shape) \n",
    "\n",
    "\n",
    "# test set에 일부 정상 값을 함께 넣어줌\n",
    "test_X_ae= np.concatenate((test_X_ae, X_abnormal), axis=0)\n",
    "test_y_ae = np.concatenate((test_y_ae, abnormal_y[ip_idx]), axis=0) \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_y_df = pd.DataFrame(test_y_ae, columns=['ip','label'])\n",
    "train_y_df = pd.DataFrame(train_y_ae, columns=['ip','label']) \n",
    "test_y_df.head() \n",
    "train_y_df.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ip = int(test_y_df.ip[0])\n",
    "cur_ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip8879 = train_X_ae.reshape(-1, 14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip8879 = pd.DataFrame(ip8879, columns=iv)\n",
    "ip8879"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, models, optimizers, utils, layers\n",
    "from keras.layers import LSTM, Dense, Activation, Conv1D, Dropout, Conv1DTranspose, BatchNormalization\n",
    "from keras.models import load_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = optimizers.RMSprop(lr=0.0001) \n",
    "adam = optimizers.Adam(lr=0.0001)\n",
    "kernel_s = 3\n",
    "seq_time = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del cnn_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "cnn_ae = models.Sequential([\n",
    "    layers.Input(shape=(seq_time, features)),\n",
    "    layers.Conv1D(filters=14, kernel_size=kernel_s, strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    layers.Conv1D(filters=16, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.BatchNormalization(), \n",
    "    Activation('relu'),\n",
    "    layers.Conv1D(filters=32, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.Conv1DTranspose(filters=32, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    layers.Conv1DTranspose(filters=16, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    layers.Conv1DTranspose(filters=14, kernel_size=kernel_s, padding='same'),\n",
    "]) \n",
    "\n",
    "cnn_ae.compile(optimizer=adam, loss='mse') \n",
    "cnn_ae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hist = cnn_ae.fit(train_X_ae, train_X_ae, epochs=50, validation_split=0.1, batch_size=16, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_ae.save('./Model/model_ip_{}'.format(cur_ip))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly\n",
    "# import plotly.graph_objects as go\n",
    "# plotly.offline.init_notebook_mode(connected=True)\n",
    "\n",
    "# loss = hist.history['loss']\n",
    "# val_loss = hist.history['val_loss']\n",
    "\n",
    "# fig = go.Figure() \n",
    "# fig.add_trace(go.Scatter(y=loss, mode='lines', name='loss'))\n",
    "# fig.add_trace(go.Scatter(y=val_loss, mode='lines', name='val_loss'))\n",
    "# fig.update_layout(height=400, width=600, title='Mix data: Loss of Convolutional AE')\n",
    "# fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = cnn_ae.predict(test_X_ae).reshape(test_X_ae.shape[0], -1)\n",
    "real = test_X_ae.reshape(test_X_ae.shape[0], -1)\n",
    "mse = np.log(np.mean(np.power(real - pred_x, 2), axis=1))\n",
    "test_df_error = pd.DataFrame({'reconstruction_error': mse, 'Label': test_y_df.label})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ddos = test_df_error[test_df_error.Label==1]\n",
    "test_normal = test_df_error[test_df_error.Label==0] \n",
    "test_normal.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = cnn_ae.predict(train_X_ae).reshape(train_X_ae.shape[0], -1)\n",
    "real = train_X_ae.reshape(train_X_ae.shape[0], -1) \n",
    "mse = np.log(np.mean(np.power(real - pred_x, 2), axis=1))\n",
    "train_df_error = pd.DataFrame({'reconstruction_error': mse, 'Label': train_y_df.label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr = train_df_error.describe()\n",
    "error = sorted(train_df_error.reconstruction_error.values, reverse=True)\n",
    "\n",
    "up_to_99_5 = int(round(len(error) * 0.005,0)) \n",
    "up_to_99_5\n",
    "\n",
    "threshold = error[up_to_99_5]\n",
    "print(thr)\n",
    "print(threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddos_num = len(test_ddos)\n",
    "if ddos_num > 10 :\n",
    "    random_count = int(round(ddos_num*0.1, 0)) \n",
    "    print('이용가능한 디도스 데이터는 {}개 입니다.'.format(random_count))\n",
    "    sampled_idx = list(np.random.randint(ddos_num, size=(random_count)))\n",
    "    sampled_threshold = [test_ddos.iloc[i,0] for i in sampled_idx]\n",
    "    difference = [i- threshold for i in sampled_threshold]\n",
    "    print(difference) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "safe_line = error[0] - threshold\n",
    "safe_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "pred_y = [1 if e > threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "\n",
    "print(confusion_matrix(test_df_error.Label, pred_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = confusion_matrix(test_df_error.Label, pred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 원래 임계치로 했을 때 \n",
    "from sklearn.metrics import classification_report, confusion_matrix, auc, roc_curve\n",
    "\n",
    "if difference != 0:\n",
    "    if min(difference)> safe_line:\n",
    "        pred_y = [ 1 if e> threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "        print('새로운 임계치 {}로 갱신되었습니다.'.format(threshold))\n",
    "    else:\n",
    "        pred_y = [ 1 if e> threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "else: \n",
    "    pred_y = [ 1 if e> threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "        \n",
    "print(classification_report(test_df_error.Label, pred_y)) \n",
    "print(confusion_matrix(test_df_error.Label, pred_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 갱신 규칙을 적용했을 때 \n",
    "if difference != 0:\n",
    "    if min(difference)> safe_line:\n",
    "        threshold = error[0] \n",
    "        pred_y = [ 1 if e> threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "        print('새로운 임계치 {}로 갱신되었습니다.'.format(threshold))\n",
    "    else:\n",
    "        pred_y = [ 1 if e> threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "else: \n",
    "    pred_y = [ 1 if e> threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "        \n",
    "print(classification_report(test_df_error.Label, pred_y)) \n",
    "print(confusion_matrix(test_df_error.Label, pred_y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fpr, tpr, thresholds = roc_curve(test_df_error.Label, pred_y)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure() \n",
    "plt.plot(fpr, tpr, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "data = [train_df_error.reconstruction_error, test_ddos.reconstruction_error, test_normal.reconstruction_error]\n",
    "group = ['normal of train', 'ddos of test', 'normal of test'] \n",
    "fig = ff.create_distplot(data, group, bin_size=[.3,.3,.3])\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.figure_factory as ff\n",
    "\n",
    "data = [train_df_error.reconstruction_error, test_normal.reconstruction_error]\n",
    "group = ['normal of train', 'normal of test'] \n",
    "fig = ff.create_distplot(data, group, bin_size=[.3,.3])\n",
    "fig.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df_error[train_df_error.reconstruction_error>-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_df_error[train_df_error.reconstruction_error<-6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "141/142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2/(1/0.892 + 1/0.992)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
