{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_list = []\n",
    "max_error_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['scaler_train_ip_14011.csv',\n",
    " 'scaler_train_ip_11614.csv',\n",
    " 'scaler_train_ip_8205.csv',\n",
    " 'scaler_train_ip_8923.csv',\n",
    " 'scaler_train_ip_16481.csv',\n",
    " 'scaler_train_ip_8879.csv',\n",
    " 'scaler_train_ip_8860.csv']\n",
    "cust_ip_list = [14011, 11614, 8205, 8923, 16481, 8879, 8860]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for i in files:\n",
    "    tmp_df = pd.read_csv('./Train/scaler_train_ip_{}.csv'.format(i)) \n",
    "    tmp_df = tmp_df.iloc[:,1:]\n",
    "    df_list.append(tmp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "iv = ['bytes', 'pkts',\n",
    "       'sip_entropy', 'dip_entropy', 'spt_entropy', 'dpt_entropy',\n",
    "       'proto_entropy', 'tcp_flags_entropy', 'icmp_ratio', 'tcp_ratio',\n",
    "       'udp_ratio', 'domestic_ratio', 'in_ratio', 'inner_ratio']\n",
    "iv1 = ['bytes', 'pkts',\n",
    "       'sip_entropy', 'dip_entropy', 'spt_entropy', 'dpt_entropy',\n",
    "       'proto_entropy', 'tcp_flags_entropy', 'icmp_ratio', 'tcp_ratio',\n",
    "       'udp_ratio', 'domestic_ratio', 'in_ratio', 'inner_ratio', 'cust_ip_no', 'event']\n",
    "features = len(iv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IP별 정규화\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib\n",
    "\n",
    "X_list = []\n",
    "y_list = [] \n",
    "for n, i in enumerate(df_list):\n",
    "    scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "    file_name = './Scaler/scaler_ip_{}.pkl'.format(cust_ip_list[n]) \n",
    "    x = scaler.fit_transform(i[iv].values) \n",
    "    x = x.reshape(-1,5,14)\n",
    "    X_list.append(x)\n",
    "    y = i.event.dropna()\n",
    "    y_list.append(y.values)\n",
    "    joblib.dump(scaler, file_name) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, models, optimizers, utils, layers\n",
    "from keras.layers import LSTM, Dense, Activation, Conv1D, Dropout, Conv1DTranspose, BatchNormalization\n",
    "from keras.models import load_model\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = optimizers.Adam(lr=0.0001)\n",
    "kernel_s = 3 \n",
    "seq_time = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "del cnn_ae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "cnn_ae = models.Sequential([\n",
    "    layers.Input(shape=(seq_time, features)),\n",
    "    layers.Conv1D(filters=14, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    layers.Conv1D(filters=16, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.BatchNormalization(), \n",
    "    Activation('relu'),\n",
    "    layers.Conv1D(filters=32, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.Conv1DTranspose(filters=32, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    layers.Conv1DTranspose(filters=16, kernel_size=kernel_s, padding='same', strides=1),\n",
    "    layers.BatchNormalization(),\n",
    "    Activation('relu'),\n",
    "    layers.Conv1DTranspose(filters=14, kernel_size=kernel_s, padding='same'),\n",
    "]) \n",
    "\n",
    "cnn_ae.compile(optimizer=adam, loss='mse') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "510/510 - 1s - loss: 0.3013 - val_loss: 0.0870\n",
      "Epoch 2/150\n",
      "510/510 - 1s - loss: 0.0460 - val_loss: 0.0264\n",
      "Epoch 3/150\n",
      "510/510 - 1s - loss: 0.0224 - val_loss: 0.0166\n",
      "Epoch 4/150\n",
      "510/510 - 1s - loss: 0.0160 - val_loss: 0.0129\n",
      "Epoch 5/150\n",
      "510/510 - 1s - loss: 0.0137 - val_loss: 0.0110\n",
      "Epoch 6/150\n",
      "510/510 - 1s - loss: 0.0123 - val_loss: 0.0099\n",
      "Epoch 7/150\n",
      "510/510 - 1s - loss: 0.0109 - val_loss: 0.0089\n",
      "Epoch 8/150\n",
      "510/510 - 1s - loss: 0.0101 - val_loss: 0.0084\n",
      "Epoch 9/150\n",
      "510/510 - 1s - loss: 0.0095 - val_loss: 0.0079\n",
      "Epoch 10/150\n",
      "510/510 - 1s - loss: 0.0088 - val_loss: 0.0075\n",
      "Epoch 11/150\n",
      "510/510 - 1s - loss: 0.0084 - val_loss: 0.0072\n",
      "Epoch 12/150\n",
      "510/510 - 1s - loss: 0.0078 - val_loss: 0.0068\n",
      "Epoch 13/150\n",
      "510/510 - 1s - loss: 0.0073 - val_loss: 0.0066\n",
      "Epoch 14/150\n",
      "510/510 - 1s - loss: 0.0069 - val_loss: 0.0063\n",
      "Epoch 15/150\n",
      "510/510 - 1s - loss: 0.0065 - val_loss: 0.0060\n",
      "Epoch 16/150\n",
      "510/510 - 1s - loss: 0.0062 - val_loss: 0.0058\n",
      "Epoch 17/150\n",
      "510/510 - 1s - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 18/150\n",
      "510/510 - 1s - loss: 0.0057 - val_loss: 0.0056\n",
      "Epoch 19/150\n",
      "510/510 - 1s - loss: 0.0054 - val_loss: 0.0053\n",
      "Epoch 20/150\n",
      "510/510 - 1s - loss: 0.0052 - val_loss: 0.0053\n",
      "Epoch 21/150\n",
      "510/510 - 1s - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 22/150\n",
      "510/510 - 1s - loss: 0.0049 - val_loss: 0.0048\n",
      "Epoch 23/150\n",
      "510/510 - 1s - loss: 0.0047 - val_loss: 0.0046\n",
      "Epoch 24/150\n",
      "510/510 - 1s - loss: 0.0046 - val_loss: 0.0046\n",
      "Epoch 25/150\n",
      "510/510 - 1s - loss: 0.0045 - val_loss: 0.0046\n",
      "Epoch 26/150\n",
      "510/510 - 1s - loss: 0.0043 - val_loss: 0.0043\n",
      "Epoch 27/150\n",
      "510/510 - 1s - loss: 0.0042 - val_loss: 0.0043\n",
      "Epoch 28/150\n",
      "510/510 - 1s - loss: 0.0041 - val_loss: 0.0041\n",
      "Epoch 29/150\n",
      "510/510 - 1s - loss: 0.0039 - val_loss: 0.0041\n",
      "Epoch 30/150\n",
      "510/510 - 1s - loss: 0.0039 - val_loss: 0.0040\n",
      "Epoch 31/150\n",
      "510/510 - 1s - loss: 0.0038 - val_loss: 0.0039\n",
      "Epoch 32/150\n",
      "510/510 - 1s - loss: 0.0037 - val_loss: 0.0039\n",
      "Epoch 33/150\n",
      "510/510 - 1s - loss: 0.0036 - val_loss: 0.0038\n",
      "Epoch 34/150\n",
      "510/510 - 1s - loss: 0.0035 - val_loss: 0.0038\n",
      "Epoch 35/150\n",
      "510/510 - 1s - loss: 0.0035 - val_loss: 0.0037\n",
      "Epoch 36/150\n",
      "510/510 - 1s - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 37/150\n",
      "510/510 - 1s - loss: 0.0034 - val_loss: 0.0036\n",
      "Epoch 38/150\n",
      "510/510 - 1s - loss: 0.0033 - val_loss: 0.0035\n",
      "Epoch 39/150\n",
      "510/510 - 1s - loss: 0.0032 - val_loss: 0.0035\n",
      "Epoch 40/150\n",
      "510/510 - 1s - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 41/150\n",
      "510/510 - 1s - loss: 0.0032 - val_loss: 0.0034\n",
      "Epoch 42/150\n",
      "510/510 - 1s - loss: 0.0031 - val_loss: 0.0034\n",
      "Epoch 43/150\n",
      "510/510 - 1s - loss: 0.0031 - val_loss: 0.0033\n",
      "Epoch 44/150\n",
      "510/510 - 1s - loss: 0.0030 - val_loss: 0.0034\n",
      "Epoch 45/150\n",
      "510/510 - 1s - loss: 0.0030 - val_loss: 0.0031\n",
      "Epoch 46/150\n",
      "510/510 - 1s - loss: 0.0030 - val_loss: 0.0032\n",
      "Epoch 47/150\n",
      "510/510 - 1s - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 48/150\n",
      "510/510 - 1s - loss: 0.0029 - val_loss: 0.0031\n",
      "Epoch 49/150\n",
      "510/510 - 1s - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 50/150\n",
      "510/510 - 1s - loss: 0.0028 - val_loss: 0.0030\n",
      "Epoch 51/150\n",
      "510/510 - 1s - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 52/150\n",
      "510/510 - 1s - loss: 0.0027 - val_loss: 0.0030\n",
      "Epoch 53/150\n",
      "510/510 - 1s - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 54/150\n",
      "510/510 - 1s - loss: 0.0027 - val_loss: 0.0029\n",
      "Epoch 55/150\n",
      "510/510 - 1s - loss: 0.0026 - val_loss: 0.0029\n",
      "Epoch 56/150\n",
      "510/510 - 1s - loss: 0.0026 - val_loss: 0.0028\n",
      "Epoch 57/150\n",
      "510/510 - 1s - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 58/150\n",
      "510/510 - 1s - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 59/150\n",
      "510/510 - 1s - loss: 0.0025 - val_loss: 0.0028\n",
      "Epoch 60/150\n",
      "510/510 - 1s - loss: 0.0025 - val_loss: 0.0027\n",
      "Epoch 61/150\n",
      "510/510 - 1s - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 62/150\n",
      "510/510 - 1s - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 63/150\n",
      "510/510 - 1s - loss: 0.0024 - val_loss: 0.0026\n",
      "Epoch 64/150\n",
      "510/510 - 1s - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 65/150\n",
      "510/510 - 1s - loss: 0.0024 - val_loss: 0.0027\n",
      "Epoch 66/150\n",
      "510/510 - 1s - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 67/150\n",
      "510/510 - 1s - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 68/150\n",
      "510/510 - 1s - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 69/150\n",
      "510/510 - 1s - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 70/150\n",
      "510/510 - 1s - loss: 0.0022 - val_loss: 0.0026\n",
      "Epoch 71/150\n",
      "510/510 - 1s - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 72/150\n",
      "510/510 - 1s - loss: 0.0023 - val_loss: 0.0025\n",
      "Epoch 73/150\n",
      "510/510 - 1s - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 74/150\n",
      "510/510 - 1s - loss: 0.0022 - val_loss: 0.0025\n",
      "Epoch 75/150\n",
      "510/510 - 1s - loss: 0.0021 - val_loss: 0.0025\n",
      "Epoch 76/150\n",
      "510/510 - 1s - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 77/150\n",
      "510/510 - 1s - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 78/150\n",
      "510/510 - 1s - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 79/150\n",
      "510/510 - 1s - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 80/150\n",
      "510/510 - 1s - loss: 0.0021 - val_loss: 0.0023\n",
      "Epoch 81/150\n",
      "510/510 - 1s - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 82/150\n",
      "510/510 - 1s - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 83/150\n",
      "510/510 - 1s - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 84/150\n",
      "510/510 - 1s - loss: 0.0020 - val_loss: 0.0024\n",
      "Epoch 85/150\n",
      "510/510 - 1s - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 86/150\n",
      "510/510 - 1s - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 87/150\n",
      "510/510 - 1s - loss: 0.0020 - val_loss: 0.0023\n",
      "Epoch 88/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 89/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 90/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 91/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 92/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 93/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 94/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 95/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 96/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 97/150\n",
      "510/510 - 1s - loss: 0.0019 - val_loss: 0.0022\n",
      "Epoch 98/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 99/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 100/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 101/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0022\n",
      "Epoch 102/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 103/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 104/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 105/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 106/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0021\n",
      "Epoch 107/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 108/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 109/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0022\n",
      "Epoch 110/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 111/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0021\n",
      "Epoch 112/150\n",
      "510/510 - 1s - loss: 0.0018 - val_loss: 0.0020\n",
      "Epoch 113/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 114/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 115/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 116/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 117/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 118/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 119/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 120/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0019\n",
      "Epoch 121/150\n",
      "510/510 - 1s - loss: 0.0017 - val_loss: 0.0020\n",
      "Epoch 122/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 123/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 124/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 125/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 126/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 127/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 128/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 129/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0020\n",
      "Epoch 130/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 131/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 132/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 133/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 134/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 135/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 136/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 137/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 138/150\n",
      "510/510 - 1s - loss: 0.0016 - val_loss: 0.0019\n",
      "Epoch 139/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 140/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 141/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 142/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 143/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 144/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 145/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 146/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 147/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0019\n",
      "Epoch 148/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 149/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0018\n",
      "Epoch 150/150\n",
      "510/510 - 1s - loss: 0.0015 - val_loss: 0.0018\n"
     ]
    }
   ],
   "source": [
    "hist = cnn_ae.fit(X_list[i], X_list[i], epochs=150, validation_split=0.1, batch_size=16, shuffle=True, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_x = cnn_ae.predict(X_list[i]).reshape(X_list[i].shape[0],-1)\n",
    "real = X_list[i].reshape(X_list[i].shape[0], -1) \n",
    "log_mse = np.log(np.mean(np.power(real-pred_x, 2), axis=1)) \n",
    "train_df_error = pd.DataFrame({'reconstruction_error':log_mse, 'Label':y_list[i]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       reconstruction_error   Label\n",
      "count           9050.000000  9050.0\n",
      "mean              -7.109068     0.0\n",
      "std                0.691800     0.0\n",
      "min               -8.636509     0.0\n",
      "25%               -7.575020     0.0\n",
      "50%               -7.236262     0.0\n",
      "75%               -6.798217     0.0\n",
      "max               -1.667522     0.0\n",
      "-4.34665793646862\n"
     ]
    }
   ],
   "source": [
    "thr = train_df_error.describe()\n",
    "error = sorted(train_df_error.reconstruction_error.values, reverse=True)\n",
    "\n",
    "up_to_99_5 = int(round(len(error) * 0.005,0)) \n",
    "up_to_99_5\n",
    "\n",
    "threshold = error[up_to_99_5] \n",
    "max_error = error[0]\n",
    "print(thr)\n",
    "print(threshold) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = pd.read_csv('./scaler_test_ip_8879.csv')\n",
    "y = test_X.iloc[:,-1]\n",
    "y = y.dropna()\n",
    "test_X = test_X.iloc[:,1:-1].values\n",
    "#scaler =joblib.load('./Scaler/scaler_ip_{}.pkl'.format(cust_ip_list[i]))\n",
    "#scaler = scaler.partial_fit(test_X)\n",
    "X = scaler.transform(test_X).reshape(-1,5,14) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1000    6]\n",
      " [   0   19]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pred_x = cnn_ae.predict(X).reshape(X.shape[0],-1)\n",
    "real = X.reshape(X.shape[0], -1)\n",
    "log_mse = np.log(np.mean(np.power(real-pred_x, 2), axis=1)) \n",
    "test_df_error = pd.DataFrame({'reconstruction_error':log_mse, 'Label':y})\n",
    "test_ddos = test_df_error[test_df_error.Label==1]\n",
    "test_normal = test_df_error[test_df_error.Label==0]  \n",
    "\n",
    "ddos_num = len(test_ddos)\n",
    "if ddos_num > 10: \n",
    "    random_count = int(round(ddos_num*0.1,0))\n",
    "    sampled_idx = list(np.random.randint(ddos_num, size=(random_count)))\n",
    "    sampled_threshold = [test_ddos.iloc[i,0] for i in sampled_idx]\n",
    "    difference = [i-threshold for i in sampled_threshold]\n",
    "    safe_line = max_error - threshold\n",
    "    if min(difference) > safe_line:\n",
    "        new_threshold = max_error\n",
    "        pred_y = [1 if e > new_threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "    else:\n",
    "        pred_y = [1 if e > threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "else:\n",
    "    pred_y = [1 if e > threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "confusion_m = confusion_matrix(y, pred_y)\n",
    "print(confusion_m)\n",
    "#confusion_m_list.append(confusion_m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_list.append(threshold) \n",
    "max_error_list.append(max_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./Model/model_ip_8879/assets\n"
     ]
    }
   ],
   "source": [
    "cnn_ae.save('./Model/model_ip_{}'.format(cust_ip_list[i]))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 맨 마지막에 한번!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "thr_max = pd.DataFrame(zip(thr_list, max_error_list), columns=['threshold','max_error'])\n",
    "thr_max\n",
    "thr_max.to_csv('./Threshold/Threshold.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_ip_list = [14011, 11614, 8205, 8923, 16481, 8879, 8860]\n",
    "confusion_m_list = []\n",
    "roc_score=[]\n",
    "acc=[] \n",
    "\n",
    "Evaluation=pd.DataFrame(np.random.randn(7,6),columns=['cust_ip_no','precision','Recall','Accuracy','F1_score','Auc_score'])\n",
    "\n",
    "\n",
    "for i in range(len(cust_ip_list)):\n",
    "    file_path='./Test_data/scaler_test_ip_{}.csv'.format(cust_ip_list[i])\n",
    "    model_path ='./Models/model_ip_{}'.format(cust_ip_list[i])\n",
    "    df=pd.read_csv(file_path) \n",
    "    model = keras.models.load_model(model_path)\n",
    "    thr_df = pd.read_csv('./Threshold/Threshold.csv')\n",
    "\n",
    "    print('ip {}의 데이터와 모델을 불러왔습니다.'.format(cust_ip_list[i]))\n",
    "\n",
    "\n",
    "    X = df.iloc[:,1:-1].values\n",
    "    X = X.reshape(-1,5,14)\n",
    "    y = df.iloc[:,-1]\n",
    "    y = y.dropna()\n",
    "    threshold = thr_df.threshold[i]\n",
    "    max_error = thr_df.max_error[i]\n",
    "    \n",
    "    pred_X = model.predict(X).reshape(X.shape[0], -1)\n",
    "    real = X.reshape(X.shape[0], -1)\n",
    "    log_mse = np.log(np.mean(np.power(real-pred_X, 2), axis=1)) \n",
    "    test_df_error = pd.DataFrame({'reconstruction_error':log_mse, 'Label':y})\n",
    "    test_df_error=test_df_error.reset_index()\n",
    "    test_ddos = test_df_error[test_df_error.Label==1]\n",
    "    test_normal = test_df_error[test_df_error.Label==0]      \n",
    "    \n",
    "    ddos_num = len(test_ddos)\n",
    "    if ddos_num > 10:\n",
    "        random_count = int(round(ddos_num*0.1,0))\n",
    "        sampled_idx = list(np.random.randint(ddos_num, size=(random_count)))\n",
    "        sampled_threshold = [test_ddos.iloc[i,0] for i in sampled_idx]\n",
    "        difference = [i-threshold for i in sampled_threshold]\n",
    "        safe_line = max_error - threshold\n",
    "        if min(difference) > safe_line:\n",
    "            new_threshold = max_error       \n",
    "            pred_y = [1 if e > new_threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "#             old_pred_y = [1 if e > threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "#             new_recall = metrics.recall_score(y, new_pred_y)\n",
    "#             old_recall = metrics.recall_score(y, old_pred_y)\n",
    "#             if old_recall > new_recall :\n",
    "#                pred_y = old_pred_y\n",
    "#             else: \n",
    "#                pred_y = new_pred_y\n",
    "#                threshold = max_error\n",
    "        else: \n",
    "            pred_y = [1 if e > threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "    else : \n",
    "        pred_y = [1 if e > threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "    \n",
    "    #pred_y = [1 if e > threshold else 0 for e in test_df_error['reconstruction_error'].values]\n",
    "    \n",
    "    \n",
    "    Prediction=pd.DataFrame(columns=['Row','real','predict'])\n",
    "    \n",
    "    Prediction['Row']=test_df_error['index']\n",
    "    Prediction['real']=list(y)\n",
    "    Prediction['predict']=pred_y\n",
    "    \n",
    "\n",
    "    roc=roc_auc_score(y,pred_y)\n",
    "    roc_score.append(roc)\n",
    "    \n",
    "    accuracy=accuracy_score(y,pred_y)\n",
    "    acc.append(accuracy)\n",
    "    \n",
    "    \n",
    "    confusion_m = confusion_matrix(y, pred_y)\n",
    "    confusion_m_list.append(confusion_m)\n",
    "    \n",
    "    Evaluation['cust_ip_no'][i]=cust_ip_list[i]\n",
    "    Evaluation['precision'][i]=round(metrics.precision_score(y, pred_y),4)\n",
    "    Evaluation['Recall'][i]=round(metrics.recall_score(y, pred_y),4)\n",
    "    Evaluation['Accuracy'][i]=round(accuracy,4)\n",
    "    Evaluation['F1_score'][i]=round(metrics.f1_score(y, pred_y),4)\n",
    "    Evaluation['Auc_score'][i]=round(roc_auc_score(y,pred_y),4)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    print('IP{}의 detection 결과입니다.'.format(cust_ip_list[i]))\n",
    "    print('Precision: {}'.format(metrics.precision_score(y, pred_y)))\n",
    "    print('Recall: {}'.format(metrics.recall_score(y, pred_y)))\n",
    "    print('F1 score: {}'.format(metrics.f1_score(y, pred_y)))   \n",
    "    print(confusion_m)\n",
    "    #print('Threshold:{}'.format(threshold))\n",
    "    #print('Max error:{}'.format(max_error))\n",
    "    print(' ')\n",
    "    \n",
    "    name='./평가지표/Scaler_label'+str(cust_ip_list[i])+'.csv'\n",
    "    Prediction.to_csv(name,encoding='ms949')\n",
    "    \n",
    "Evaluation.to_csv('./평가지표/Scaler_Evaluation.csv',encoding='ms949')\n",
    "    \n",
    "    \n",
    "final_m = sum(confusion_m_list)\n",
    "precision = round(final_m[1][1]/(final_m[1][1]+final_m[0][1]),2)\n",
    "recall = round(final_m[1][1]/(final_m[1][1]+final_m[1][0]), 2)\n",
    "f1_score = round(2/((1/precision)+(1/recall)),2)\n",
    "\n",
    "print('==============================')\n",
    "print('모든 IP에 대한 detection 결과입니다.')\n",
    "print(final_m)\n",
    "print('Precision: {}'.format(round(precision,4)))\n",
    "print('Recall: {}'.format(round(recall,4)))\n",
    "print('Accuracy: {}'.format(round(sum(acc)/len(acc),4)))                 \n",
    "print('F1 score: {}'.format(round(f1_score,4))) \n",
    "print('Auc_Score: {}'.format(round(sum(roc_score)/len(roc_score),4)))\n",
    "\n",
    "print('**각 CUST_IP_NO 별 평가지표는 평가지표 파일에 저장 되었습니다.**')    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
